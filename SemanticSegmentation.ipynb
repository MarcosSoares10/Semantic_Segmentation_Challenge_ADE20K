{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwmbpJGOcVN1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Dropout, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKgaV_P_cbz8"
      },
      "source": [
        "#Dataset\n",
        "#http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\n",
        "\n",
        "!wget http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\n",
        "!unzip ADEChallengeData2016.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqlDhjYRltnp"
      },
      "source": [
        "def createConvolutionBlock(inputs, filters, pool=False, dropout=False, dilation=False):\n",
        "    initializer = 'he_normal'\n",
        "\n",
        "    if dilation:\n",
        "        if filters>=32:\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(inputs)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(2,2), kernel_initializer=initializer, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(3,3), kernel_initializer=initializer, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "        else:\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(inputs)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(2,2), kernel_initializer=initializer, padding='same')(x)\n",
        "            x = BatchNormalization()(x)           \n",
        "        \n",
        "        if pool:\n",
        "            pl = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "            if dropout:\n",
        "                x = Dropout(0.20)(x)\n",
        "            return x, pl\n",
        "        else:\n",
        "            if dropout:\n",
        "                x = Dropout(0.20)(x)\n",
        "            return x\n",
        "\n",
        "    else:\n",
        "        y = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(inputs)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        \n",
        "        if pool:\n",
        "            pool_ = MaxPooling2D((2,2))(y)\n",
        "            if dropout:\n",
        "                y = Dropout(0.20)(y)\n",
        "            return y, pool_\n",
        "        else:\n",
        "            if dropout:\n",
        "                y = Dropout(0.20)(y)\n",
        "            return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-036nDVl54U"
      },
      "source": [
        "def createDecoderBlock(inputlayer, concatlayer, filters):\n",
        "    x = concatenate([Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputlayer), concatlayer], axis=3) \n",
        "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrfChlKnl6mO"
      },
      "source": [
        "def build_model_architecture(shape, num_classes):\n",
        "    inputs = Input(shape)\n",
        "\n",
        "    actv2, pl2 = createConvolutionBlock(inputs, 8, pool=True, dropout=True, dilation=True)\n",
        "    actv3, pl3 = createConvolutionBlock(pl2, 16, pool=True, dropout=True, dilation=True)\n",
        "    actv4, pl4 = createConvolutionBlock(pl3, 32, pool=True, dropout=True, dilation=True)\n",
        "    actv5, pl5 = createConvolutionBlock(pl4, 64, pool=True, dropout=True, dilation=True)\n",
        "    actv6, pl6 = createConvolutionBlock(pl5, 128, pool=True, dropout=True, dilation=True)\n",
        "\n",
        "\n",
        "    bridge = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pl6)\n",
        "    bridge = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(bridge)\n",
        "\n",
        "\n",
        "    dec1 = createDecoderBlock(bridge, actv6, 128)\n",
        "    dec2 = createDecoderBlock(dec1, actv5, 64)\n",
        "    dec3 = createDecoderBlock(dec2, actv4, 32)\n",
        "    dec4 = createDecoderBlock(dec3, actv3, 16)\n",
        "    dec5 = createDecoderBlock(dec4, actv2, 8)\n",
        "\n",
        "    output = Conv2D(num_classes, (1,1), padding=\"same\", activation=\"softmax\")(dec5)\n",
        "\n",
        "    return Model(inputs, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJgaCxeCl8-8"
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# avg blur minimum filcv2.cvtColor(image, cv2.COLOR_BGR2GRAY)ter size is 3\n",
        "def avg_blur(img, max_filiter_size = 3) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\tif max_filiter_size >= 3 :\n",
        "\t\tfilter_size = random.randint(3, max_filiter_size)\n",
        "\t\tif filter_size % 2 == 0 :\n",
        "\t\t\tfilter_size += 1\n",
        "\t\tout = cv2.blur(img, (filter_size, filter_size))\n",
        "\treturn out\n",
        "\n",
        "# gaussain blur minimum filter size is 3\n",
        "# when sigma = 0 gaussain blur weight will compute by program\n",
        "# when the sigma is more large the blur effect more obvious\n",
        "\n",
        "def gaussain_blur(img, max_filiter_size = 3, sigma = 0) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\tif max_filiter_size >= 3 :\n",
        "\t\tfilter_size = random.randint(3, max_filiter_size)\n",
        "\t\tif filter_size % 2 == 0 :\n",
        "\t\t\tfilter_size += 1\n",
        "\t\t#print ('size = %d'% filter_size)\n",
        "\t\tout = cv2.GaussianBlur(img, (filter_size, filter_size), sigma)\n",
        "\treturn out\n",
        "\n",
        "def gaussain_noise(img, mean = 0, var = 0.1) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\th, w, c = img.shape\n",
        "\tsigma = var ** 0.5\n",
        "\tgauss = np.random.normal(mean, sigma, (h, w, c))\n",
        "\tgauss = gauss.reshape(h, w, c).astype(np.uint8)\n",
        "\tnoisy = img + gauss\n",
        "\treturn noisy\n",
        "\n",
        "# fill_pixel is 0(black) or 255(white)\n",
        "def img_shift(img,mask, x_min_shift_piexl = -1, x_max_shift_piexl = 1, y_min_shift_piexl = -1, y_max_shift_piexl = 1, fill_pixel = 0):\n",
        "  img = img.astype(np.uint8)\n",
        "  h, w, c = img.shape\n",
        "  out = np.zeros(img.shape)\n",
        "  maskout = np.zeros(mask.shape)\n",
        "\t\n",
        "  if fill_pixel == 255:\n",
        "    out[:, :] = 255\n",
        "  out = out.astype(np.uint8)\n",
        "  maskout = maskout.astype(np.uint8)\n",
        "  \n",
        "  move_x = random.randint(x_min_shift_piexl, x_max_shift_piexl)\n",
        "  move_y = random.randint(y_min_shift_piexl, y_max_shift_piexl)\n",
        " \n",
        "  if move_x >= 0 and move_y >= 0 :\n",
        "    out[move_y:, move_x: ] = img[0: (h - move_y), 0: (w - move_x)]\n",
        "    maskout[move_y:, move_x: ] = mask[0: (h - move_y), 0: (w - move_x)]\n",
        "  elif move_x < 0 and move_y < 0 :\n",
        "    out[0: (h + move_y), 0: (w + move_x)] = img[ - move_y:, - move_x:]\n",
        "    maskout[0: (h + move_y), 0: (w + move_x)] = mask[ - move_y:, - move_x:]\n",
        "  elif move_x >= 0 and move_y < 0 :\n",
        "    out[0: (h + move_y), move_x:] = img[ - move_y:, 0: (w - move_x)]\n",
        "    maskout[0: (h + move_y), move_x:] = mask[ - move_y:, 0: (w - move_x)]\n",
        "  elif move_x < 0 and move_y >= 0 :\n",
        "    out[move_y:, 0: (w + move_x)] = img[0 : (h - move_y), - move_x:]\n",
        "    maskout[move_y:, 0: (w + move_x)] = mask[0 : (h - move_y), - move_x:]\n",
        "    \n",
        "  return out,maskout\n",
        "\n",
        "\n",
        "# In img_flip func. it will random filp image\n",
        "# when flip factor is 1 it will do hor. flip (Horizontal)\n",
        "#\t\t\t\t\t  0            ver. flip (Vertical)\n",
        "#\t\t\t\t\t -1\t\t\t   hor. + ver flip\n",
        "def img_flip(img,mask):\n",
        "  img = img.astype(np.uint8)\n",
        "  flip_factor = random.randint(-1, 1)\n",
        "  out = cv2.flip(img, flip_factor)\n",
        "  maskout = cv2.flip(mask, flip_factor)\n",
        "  return out,maskout\n",
        "\n",
        "\n",
        "# change image contrast by hsv\n",
        "def img_contrast(img, min_s, max_s, min_v, max_v) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\thsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\t_s = random.randint(min_s, max_s)\n",
        "\t_v = random.randint(min_v, max_v)\n",
        "\tif _s >= 0 :\n",
        "\t\thsv_img[:, :, 1] += _s\n",
        "\telse :\n",
        "\t\t_s = - _s\n",
        "\t\thsv_img[:, :, 1] -= _s\n",
        "\tif _v >= 0 :\n",
        "\t\thsv_img[:, :, 2] += _v\n",
        "\telse :\n",
        "\t\t_v = - _v\n",
        "\t\thsv_img[:, :, 2] += _v\n",
        "\tout = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n",
        "\treturn out\n",
        "\n",
        "#Edge enhance\n",
        "def sharpen_img(img):\n",
        "    kernel = np.array([[-1,-1,-1,-1,-1],\n",
        "                    [-1,2,2,2,-1],\n",
        "                    [-1,2,8,2,-1],\n",
        "                    [-2,2,2,2,-1],\n",
        "                    [-1,-1,-1,-1,-1]])/8.0\n",
        "    result=cv2.filter2D(img,-1,kernel)\n",
        "    return result\n",
        "\n",
        "\n",
        "def create_augment_data(arrayimgs,arraymasks,generate_qty):\n",
        "\n",
        "  auxarrayimgs = arrayimgs.copy()\n",
        "  auxarraymasks = arraymasks.copy()\n",
        "\n",
        "  # parameter for data augment functions\n",
        "  _max_filiter_size = 5 \t\t#for avg_blur and gaussain_blur\n",
        "  _sigma = 0 \t\t\t\t\t# for gaussain_blur\n",
        "\n",
        "  _mean = 0 \t\t\t\t\t# for gaussain_noise\n",
        "  _var = 0.1\t\t\t\t\t# for gaussain_noise\n",
        "\n",
        "  _x_min_shift_piexl = -20 \t# for img_shift\n",
        "  _x_max_shift_piexl = 20 \t# for img_shift\n",
        "  _y_min_shift_piexl = -20 \t# for img_shift\n",
        "  _y_max_shift_piexl = 20\t\t# for img_shift\n",
        "  _fill_pixel = 255\t\t\t# for img_shift\n",
        "\n",
        "\n",
        "  _min_s = -10\t\t\t\t# for img_contrast\n",
        "  _max_s = 10\t\t\t\t\t# for img_contrast\n",
        "  _min_v = -10\t\t\t\t# for img_contrast\n",
        "  _max_v = 10\t\t\t\t\t# for img_contrast\n",
        "\n",
        "\n",
        "\n",
        "  for index in range(len(arrayimgs)):\n",
        "    generate_quantity = generate_qty\n",
        "    while generate_quantity > 0:\n",
        "      \n",
        "      img = arrayimgs[index]\n",
        "      mask = arraymasks[index]\n",
        "\t\t\t\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = avg_blur(img, _max_filiter_size)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = gaussain_blur(img, _max_filiter_size, _sigma)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = gaussain_noise(img, _mean, _var)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img,mask = img_shift(img, mask, _x_min_shift_piexl, _x_max_shift_piexl, _y_min_shift_piexl, _y_max_shift_piexl, _fill_pixel)\n",
        "        \n",
        "      if random.randint(0, 1) == 1:\n",
        "        img,mask = img_flip(img, mask)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = img_contrast(img, _min_s, _max_s, _min_v, _max_v)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = sharpen_img(img)\n",
        "      \n",
        "      auxarrayimgs.append(img)\n",
        "      auxarraymasks.append(mask)\n",
        "\n",
        "      generate_quantity -=1\n",
        "\n",
        "  return auxarrayimgs, auxarraymasks\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwhn0hmym7cM"
      },
      "source": [
        "def set_color(pixel,mapping_colors):\n",
        "  r,g,b = 0,0,0\n",
        "  for colors in mapping_colors:\n",
        "    c = colors[0]\n",
        "    if int(c) == pixel:\n",
        "      rgb = colors[1]\n",
        "      r,g,b = rgb[1:len(rgb)-1].split(',')\n",
        "      break\n",
        "  return int(r),int(g),int(b)\n",
        "\n",
        "def mapping_labels_color(img,mapping_colors):\n",
        "  for x in range(img.shape[0]):\n",
        "    for y in range(img.shape[1]):\n",
        "      if img[x,y,0] != 0:\n",
        "        img[x,y,0],img[x,y,1],img[x,y,2] = set_color(img[x,y,0],mapping_colors)\n",
        "  return img\n",
        "\n",
        "def resizeimgsforModel(img,size):\n",
        "  #auximglist = []\n",
        "  dim = (size, size)\n",
        "  #for item in img:\n",
        "  resized = cv2.resize(img, dim, interpolation = cv2.INTER_NEAREST)\n",
        "  #auximglist.append(resized)\n",
        "  return resized\n",
        "\n",
        "def load_dataset(path,IMG_SIZE):\n",
        " \n",
        "  \n",
        "  imgfile = []\n",
        "  maskfile = []\n",
        "\n",
        "  imgtrain = []\n",
        "  masktrain = []\n",
        "\n",
        "  imgtest = []\n",
        "  masktest = []\n",
        "  \n",
        "  pathImages = os.listdir(path+\"/images/training/\")\n",
        "  pathImages.sort()\n",
        "  pathMasks = os.listdir(path+\"/annotations/training/\")\n",
        "  pathMasks.sort()\n",
        "\n",
        "  mapping_colors = []\n",
        "  csv_file =  open('color_coding/color_coding_semantic_segmentation_classes.csv', mode='r')\n",
        "  csv_reader = csv.DictReader(csv_file)\n",
        "\n",
        "  for row in csv_reader:\n",
        "    mapping_colors.append([row['Idx'],row['Color_Code (R,G,B)']])\n",
        "\n",
        "  for index in range(len(pathImages)):\n",
        "    imgfile.append(path+\"/images/training/\"+pathImages[index])\n",
        "    maskfile.append(path+\"/annotations/training/\"+pathMasks[index])\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(imgfile, maskfile, test_size=0.2, random_state=42)\n",
        "  \n",
        "  #Loading Train\n",
        "  for imgtr in range(len(X_train)):\n",
        "    img = cv2.imread(X_train[imgtr])\n",
        "    imgtrain.append(resizeimgsforModel(img,IMG_SIZE))\n",
        "\n",
        "    mask = cv2.imread(y_train[imgtr])\n",
        "    mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
        "    mask = resizeimgsforModel(mask,IMG_SIZE)\n",
        "    #mask = mapping_labels_color(mask,mapping_colors)\n",
        "\n",
        "    masktrain.append(mask)\n",
        "\n",
        "  \n",
        "  #Loading Test\n",
        "  for imgte in range(len(X_test)):\n",
        "    img = cv2.imread(X_test[imgte])\n",
        "    imgtest.append(resizeimgsforModel(img,IMG_SIZE))\n",
        "\n",
        "    mask = cv2.imread(y_test[imgte])\n",
        "    mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
        "    mask = resizeimgsforModel(mask,IMG_SIZE)\n",
        "    #mask = mapping_labels_color(mask,mapping_colors)\n",
        "    masktest.append(mask)\n",
        "    \n",
        "      \n",
        "\n",
        "  return (imgtrain,masktrain,imgtest,masktest)\n",
        "\n",
        "def load_data(dataset_path,IMG_SIZE,generate_quantity):\n",
        "    imgtrain,masktrain,imgtest,masktest = load_dataset(dataset_path,IMG_SIZE)\n",
        "\n",
        "    #Data augmentation\n",
        "    #imgtrain,masktrain = create_augment_data(imgtrain,masktrain,generate_quantity)\n",
        "\n",
        "    imgtrain = np.array(imgtrain)\n",
        "    masktrain = np.array(masktrain)\n",
        "\n",
        "    imgtest = np.array(imgtest)\n",
        "    masktest = np.array(masktest)\n",
        "\n",
        "\n",
        "    imgtrain = imgtrain.astype(np.float32)\n",
        "    imgtest = imgtest.astype(np.float32)\n",
        "\n",
        "    imgtrain = imgtrain / 255.0\n",
        "    imgtest = imgtest / 255.0\n",
        "\n",
        "    return (imgtrain, masktrain, imgtest, masktest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uvsDiqFmGyk"
      },
      "source": [
        "dataset_path = \"ADEChallengeData2016\"\n",
        "IMG_SIZE = 128\n",
        "generate_quantity = 2\n",
        "\n",
        "imgtrain,masktrain,imgtest,masktest = load_data(dataset_path,IMG_SIZE,generate_quantity)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAAB01NJmS29"
      },
      "source": [
        "N_CHANNELS = 3\n",
        "N_CLASSES = 151\n",
        "batch_size = 100\n",
        "epochs = 20\n",
        "\n",
        "train_steps = len(imgtrain) // batch_size\n",
        "validation_steps = len(imgtest) // batch_size\n",
        "input_size = (IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
        "model = build_model_architecture(input_size, N_CLASSES)\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss = loss, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhe5IehmQfE"
      },
      "source": [
        "\n",
        "#model.summary()\n",
        "\n",
        "#$ tensorboard --log_dir=logs/\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "    horizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "            ModelCheckpoint(\"pretreinedmodels/model.val_loss={val_loss:.5f}.h5\", monitor='val_loss', verbose=1, save_best_model=True),\n",
        "            EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1),\n",
        "            TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "        ]\n",
        "\n",
        "model.fit(aug.flow(imgtrain, masktrain, batch_size=batch_size),\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_data=(imgtest,masktest),\n",
        "            validation_steps=validation_steps,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            callbacks=callbacks\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}