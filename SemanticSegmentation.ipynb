{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwmbpJGOcVN1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Dropout, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKgaV_P_cbz8"
      },
      "source": [
        "#Dataset\n",
        "#http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\n",
        "\n",
        "!wget http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\n",
        "!unzip ADEChallengeData2016.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqlDhjYRltnp"
      },
      "source": [
        "def createConvolutionBlock(inputs, filters, pool=False, dropout=False, dilation=False):\n",
        "    initializer = 'he_normal'\n",
        "\n",
        "    if dilation:\n",
        "        if filters>=32:\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(inputs)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(2,2), kernel_initializer=initializer, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(3,3), kernel_initializer=initializer, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "        else:\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(inputs)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(2,2), kernel_initializer=initializer, padding='same')(x)\n",
        "            x = BatchNormalization()(x)           \n",
        "        \n",
        "        if pool:\n",
        "            pl = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "            if dropout:\n",
        "                x = Dropout(0.20)(x)\n",
        "            return x, pl\n",
        "        else:\n",
        "            if dropout:\n",
        "                x = Dropout(0.20)(x)\n",
        "            return x\n",
        "\n",
        "    else:\n",
        "        y = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(inputs)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Conv2D(filters, (3, 3), activation='relu',dilation_rate=(1,1), kernel_initializer=initializer, padding='same')(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        \n",
        "        if pool:\n",
        "            pool_ = MaxPooling2D((2,2))(y)\n",
        "            if dropout:\n",
        "                y = Dropout(0.20)(y)\n",
        "            return y, pool_\n",
        "        else:\n",
        "            if dropout:\n",
        "                y = Dropout(0.20)(y)\n",
        "            return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-036nDVl54U"
      },
      "source": [
        "def createDecoderBlock(inputlayer, concatlayer, filters):\n",
        "    x = concatenate([Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputlayer), concatlayer], axis=3) \n",
        "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrfChlKnl6mO"
      },
      "source": [
        "def build_model_architecture(shape, num_classes):\n",
        "    inputs = Input(shape)\n",
        "\n",
        "    actv2, pl2 = createConvolutionBlock(inputs, 8, pool=True, dropout=True, dilation=True)\n",
        "    actv3, pl3 = createConvolutionBlock(pl2, 16, pool=True, dropout=True, dilation=True)\n",
        "    actv4, pl4 = createConvolutionBlock(pl3, 32, pool=True, dropout=True, dilation=True)\n",
        "    actv5, pl5 = createConvolutionBlock(pl4, 64, pool=True, dropout=True, dilation=True)\n",
        "    actv6, pl6 = createConvolutionBlock(pl5, 128, pool=True, dropout=True, dilation=True)\n",
        "\n",
        "\n",
        "    bridge = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pl6)\n",
        "    bridge = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(bridge)\n",
        "\n",
        "\n",
        "    dec1 = createDecoderBlock(bridge, actv6, 128)\n",
        "    dec2 = createDecoderBlock(dec1, actv5, 64)\n",
        "    dec3 = createDecoderBlock(dec2, actv4, 32)\n",
        "    dec4 = createDecoderBlock(dec3, actv3, 16)\n",
        "    dec5 = createDecoderBlock(dec4, actv2, 8)\n",
        "\n",
        "    output = Conv2D(num_classes, (1,1), padding=\"same\", activation=\"softmax\")(dec5)\n",
        "\n",
        "    return Model(inputs, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJgaCxeCl8-8"
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# avg blur minimum filcv2.cvtColor(image, cv2.COLOR_BGR2GRAY)ter size is 3\n",
        "def avg_blur(img, max_filiter_size = 3) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\tif max_filiter_size >= 3 :\n",
        "\t\tfilter_size = random.randint(3, max_filiter_size)\n",
        "\t\tif filter_size % 2 == 0 :\n",
        "\t\t\tfilter_size += 1\n",
        "\t\tout = cv2.blur(img, (filter_size, filter_size))\n",
        "\treturn out\n",
        "\n",
        "# gaussain blur minimum filter size is 3\n",
        "# when sigma = 0 gaussain blur weight will compute by program\n",
        "# when the sigma is more large the blur effect more obvious\n",
        "\n",
        "def gaussain_blur(img, max_filiter_size = 3, sigma = 0) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\tif max_filiter_size >= 3 :\n",
        "\t\tfilter_size = random.randint(3, max_filiter_size)\n",
        "\t\tif filter_size % 2 == 0 :\n",
        "\t\t\tfilter_size += 1\n",
        "\t\t#print ('size = %d'% filter_size)\n",
        "\t\tout = cv2.GaussianBlur(img, (filter_size, filter_size), sigma)\n",
        "\treturn out\n",
        "\n",
        "def gaussain_noise(img, mean = 0, var = 0.1) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\th, w, c = img.shape\n",
        "\tsigma = var ** 0.5\n",
        "\tgauss = np.random.normal(mean, sigma, (h, w, c))\n",
        "\tgauss = gauss.reshape(h, w, c).astype(np.uint8)\n",
        "\tnoisy = img + gauss\n",
        "\treturn noisy\n",
        "\n",
        "# fill_pixel is 0(black) or 255(white)\n",
        "def img_shift(img,mask, x_min_shift_piexl = -1, x_max_shift_piexl = 1, y_min_shift_piexl = -1, y_max_shift_piexl = 1, fill_pixel = 0):\n",
        "  img = img.astype(np.uint8)\n",
        "  h, w, c = img.shape\n",
        "  out = np.zeros(img.shape)\n",
        "  maskout = np.zeros(mask.shape)\n",
        "\t\n",
        "  if fill_pixel == 255:\n",
        "    out[:, :] = 255\n",
        "  out = out.astype(np.uint8)\n",
        "  maskout = maskout.astype(np.uint8)\n",
        "  \n",
        "  move_x = random.randint(x_min_shift_piexl, x_max_shift_piexl)\n",
        "  move_y = random.randint(y_min_shift_piexl, y_max_shift_piexl)\n",
        " \n",
        "  if move_x >= 0 and move_y >= 0 :\n",
        "    out[move_y:, move_x: ] = img[0: (h - move_y), 0: (w - move_x)]\n",
        "    maskout[move_y:, move_x: ] = mask[0: (h - move_y), 0: (w - move_x)]\n",
        "  elif move_x < 0 and move_y < 0 :\n",
        "    out[0: (h + move_y), 0: (w + move_x)] = img[ - move_y:, - move_x:]\n",
        "    maskout[0: (h + move_y), 0: (w + move_x)] = mask[ - move_y:, - move_x:]\n",
        "  elif move_x >= 0 and move_y < 0 :\n",
        "    out[0: (h + move_y), move_x:] = img[ - move_y:, 0: (w - move_x)]\n",
        "    maskout[0: (h + move_y), move_x:] = mask[ - move_y:, 0: (w - move_x)]\n",
        "  elif move_x < 0 and move_y >= 0 :\n",
        "    out[move_y:, 0: (w + move_x)] = img[0 : (h - move_y), - move_x:]\n",
        "    maskout[move_y:, 0: (w + move_x)] = mask[0 : (h - move_y), - move_x:]\n",
        "    \n",
        "  return out,maskout\n",
        "\n",
        "\n",
        "# In img_flip func. it will random filp image\n",
        "# when flip factor is 1 it will do hor. flip (Horizontal)\n",
        "#\t\t\t\t\t  0            ver. flip (Vertical)\n",
        "#\t\t\t\t\t -1\t\t\t   hor. + ver flip\n",
        "def img_flip(img,mask):\n",
        "  img = img.astype(np.uint8)\n",
        "  flip_factor = random.randint(-1, 1)\n",
        "  out = cv2.flip(img, flip_factor)\n",
        "  maskout = cv2.flip(mask, flip_factor)\n",
        "  return out,maskout\n",
        "\n",
        "\n",
        "# change image contrast by hsv\n",
        "def img_contrast(img, min_s, max_s, min_v, max_v) :\n",
        "\timg = img.astype(np.uint8)\n",
        "\thsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\t_s = random.randint(min_s, max_s)\n",
        "\t_v = random.randint(min_v, max_v)\n",
        "\tif _s >= 0 :\n",
        "\t\thsv_img[:, :, 1] += _s\n",
        "\telse :\n",
        "\t\t_s = - _s\n",
        "\t\thsv_img[:, :, 1] -= _s\n",
        "\tif _v >= 0 :\n",
        "\t\thsv_img[:, :, 2] += _v\n",
        "\telse :\n",
        "\t\t_v = - _v\n",
        "\t\thsv_img[:, :, 2] += _v\n",
        "\tout = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n",
        "\treturn out\n",
        "\n",
        "#Edge enhance\n",
        "def sharpen_img(img):\n",
        "    kernel = np.array([[-1,-1,-1,-1,-1],\n",
        "                    [-1,2,2,2,-1],\n",
        "                    [-1,2,8,2,-1],\n",
        "                    [-2,2,2,2,-1],\n",
        "                    [-1,-1,-1,-1,-1]])/8.0\n",
        "    result=cv2.filter2D(img,-1,kernel)\n",
        "    return result\n",
        "\n",
        "\n",
        "def create_augment_data(arrayimgs,arraymasks,generate_qty):\n",
        "\n",
        "  auxarrayimgs = arrayimgs.copy()\n",
        "  auxarraymasks = arraymasks.copy()\n",
        "\n",
        "  # parameter for data augment functions\n",
        "  _max_filiter_size = 5 \t\t#for avg_blur and gaussain_blur\n",
        "  _sigma = 0 \t\t\t\t\t# for gaussain_blur\n",
        "\n",
        "  _mean = 0 \t\t\t\t\t# for gaussain_noise\n",
        "  _var = 0.1\t\t\t\t\t# for gaussain_noise\n",
        "\n",
        "  _x_min_shift_piexl = -20 \t# for img_shift\n",
        "  _x_max_shift_piexl = 20 \t# for img_shift\n",
        "  _y_min_shift_piexl = -20 \t# for img_shift\n",
        "  _y_max_shift_piexl = 20\t\t# for img_shift\n",
        "  _fill_pixel = 255\t\t\t# for img_shift\n",
        "\n",
        "\n",
        "  _min_s = -10\t\t\t\t# for img_contrast\n",
        "  _max_s = 10\t\t\t\t\t# for img_contrast\n",
        "  _min_v = -10\t\t\t\t# for img_contrast\n",
        "  _max_v = 10\t\t\t\t\t# for img_contrast\n",
        "\n",
        "\n",
        "\n",
        "  for index in range(len(arrayimgs)):\n",
        "    generate_quantity = generate_qty\n",
        "    while generate_quantity > 0:\n",
        "      \n",
        "      img = arrayimgs[index]\n",
        "      mask = arraymasks[index]\n",
        "\t\t\t\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = avg_blur(img, _max_filiter_size)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = gaussain_blur(img, _max_filiter_size, _sigma)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = gaussain_noise(img, _mean, _var)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img,mask = img_shift(img, mask, _x_min_shift_piexl, _x_max_shift_piexl, _y_min_shift_piexl, _y_max_shift_piexl, _fill_pixel)\n",
        "        \n",
        "      if random.randint(0, 1) == 1:\n",
        "        img,mask = img_flip(img, mask)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = img_contrast(img, _min_s, _max_s, _min_v, _max_v)\n",
        "\n",
        "      if random.randint(0, 1) == 1:\n",
        "        img = sharpen_img(img)\n",
        "      \n",
        "      auxarrayimgs.append(img)\n",
        "      auxarraymasks.append(mask)\n",
        "\n",
        "      generate_quantity -=1\n",
        "\n",
        "  return auxarrayimgs, auxarraymasks\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwhn0hmym7cM"
      },
      "source": [
        "def set_color(pixel,mapping_colors):\n",
        "  r,g,b = 0,0,0\n",
        "  for colors in mapping_colors:\n",
        "    c = colors[0]\n",
        "    if int(c) == pixel:\n",
        "      rgb = colors[1]\n",
        "      r,g,b = rgb[1:len(rgb)-1].split(',')\n",
        "      break\n",
        "  return int(r),int(g),int(b)\n",
        "\n",
        "def mapping_labels_color(img,mapping_colors):\n",
        "  for x in range(img.shape[0]):\n",
        "    for y in range(img.shape[1]):\n",
        "      if img[x,y,0] != 0:\n",
        "        img[x,y,0],img[x,y,1],img[x,y,2] = set_color(img[x,y,0],mapping_colors)\n",
        "  return img\n",
        "\n",
        "def resizeimgsforModel(img,size):\n",
        "  #auximglist = []\n",
        "  dim = (size, size)\n",
        "  #for item in img:\n",
        "  resized = cv2.resize(img, dim, interpolation = cv2.INTER_NEAREST)\n",
        "  #auximglist.append(resized)\n",
        "  return resized\n",
        "\n",
        "def load_dataset(path,IMG_SIZE):\n",
        " \n",
        "  \n",
        "  imgfile = []\n",
        "  maskfile = []\n",
        "\n",
        "  imgtrain = []\n",
        "  masktrain = []\n",
        "\n",
        "  imgtest = []\n",
        "  masktest = []\n",
        "  \n",
        "  pathImages = os.listdir(path+\"/images/training/\")\n",
        "  pathImages.sort()\n",
        "  pathMasks = os.listdir(path+\"/annotations/training/\")\n",
        "  pathMasks.sort()\n",
        "\n",
        "  mapping_colors = []\n",
        "  csv_file =  open('color_coding/color_coding_semantic_segmentation_classes.csv', mode='r')\n",
        "  csv_reader = csv.DictReader(csv_file)\n",
        "\n",
        "  for row in csv_reader:\n",
        "    mapping_colors.append([row['Idx'],row['Color_Code (R,G,B)']])\n",
        "\n",
        "  for index in range(len(pathImages)):\n",
        "    imgfile.append(path+\"/images/training/\"+pathImages[index])\n",
        "    maskfile.append(path+\"/annotations/training/\"+pathMasks[index])\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(imgfile, maskfile, test_size=0.2, random_state=42)\n",
        "  \n",
        "  #Loading Train\n",
        "  for imgtr in range(len(X_train)):\n",
        "    img = cv2.imread(X_train[imgtr])\n",
        "    imgtrain.append(resizeimgsforModel(img,IMG_SIZE))\n",
        "\n",
        "    mask = cv2.imread(y_train[imgtr])\n",
        "    mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
        "    mask = resizeimgsforModel(mask,IMG_SIZE)\n",
        "    #mask = mapping_labels_color(mask,mapping_colors)\n",
        "\n",
        "    masktrain.append(mask)\n",
        "\n",
        "  \n",
        "  #Loading Test\n",
        "  for imgte in range(len(X_test)):\n",
        "    img = cv2.imread(X_test[imgte])\n",
        "    imgtest.append(resizeimgsforModel(img,IMG_SIZE))\n",
        "\n",
        "    mask = cv2.imread(y_test[imgte])\n",
        "    mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
        "    mask = resizeimgsforModel(mask,IMG_SIZE)\n",
        "    #mask = mapping_labels_color(mask,mapping_colors)\n",
        "    masktest.append(mask)\n",
        "    \n",
        "      \n",
        "\n",
        "  return (imgtrain,masktrain,imgtest,masktest)\n",
        "\n",
        "def load_data(dataset_path,IMG_SIZE,generate_quantity):\n",
        "    imgtrain,masktrain,imgtest,masktest = load_dataset(dataset_path,IMG_SIZE)\n",
        "\n",
        "    #Data augmentation\n",
        "    #imgtrain,masktrain = create_augment_data(imgtrain,masktrain,generate_quantity)\n",
        "\n",
        "    imgtrain = np.array(imgtrain)\n",
        "    masktrain = np.array(masktrain)\n",
        "\n",
        "    imgtest = np.array(imgtest)\n",
        "    masktest = np.array(masktest)\n",
        "\n",
        "\n",
        "    imgtrain = imgtrain.astype(np.float32)\n",
        "    imgtest = imgtest.astype(np.float32)\n",
        "\n",
        "    imgtrain = imgtrain / 255.0\n",
        "    imgtest = imgtest / 255.0\n",
        "\n",
        "    return (imgtrain, masktrain, imgtest, masktest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uvsDiqFmGyk"
      },
      "source": [
        "dataset_path = \"ADEChallengeData2016\"\n",
        "IMG_SIZE = 128\n",
        "generate_quantity = 2\n",
        "\n",
        "imgtrain,masktrain,imgtest,masktest = load_data(dataset_path,IMG_SIZE,generate_quantity)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAAB01NJmS29"
      },
      "source": [
        "N_CHANNELS = 3\n",
        "N_CLASSES = 151\n",
        "batch_size = 100\n",
        "epochs = 20\n",
        "\n",
        "train_steps = len(imgtrain) // batch_size\n",
        "validation_steps = len(imgtest) // batch_size\n",
        "input_size = (IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
        "model = build_model_architecture(input_size, N_CLASSES)\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss = loss, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhe5IehmQfE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "f49e5835-601c-49c6-ee00-c1faa4c3fa2e"
      },
      "source": [
        "\n",
        "#model.summary()\n",
        "\n",
        "#$ tensorboard --log_dir=logs/\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "    horizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "            ModelCheckpoint(\"pretreinedmodels/model.val_loss={val_loss:.5f}.h5\", monitor='val_loss', verbose=1, save_best_model=True),\n",
        "            EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1),\n",
        "            TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "        ]\n",
        "\n",
        "model.fit(aug.flow(imgtrain, masktrain, batch_size=batch_size),\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_data=(imgtest,masktest),\n",
        "            validation_steps=validation_steps,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            callbacks=callbacks\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  1/161 [..............................] - ETA: 0s - loss: 5.0658 - accuracy: 0.0061WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "137/161 [========================>.....] - ETA: 11s - loss: 3.5730 - accuracy: 0.2076"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6c3ceffa850e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "H0-sr87Ivx6c",
        "outputId": "41cce1f3-05cd-48e8-bad4-ca91f8ff5ab5"
      },
      "source": [
        "\n",
        "def set_color(pixel,mapping_colors):\n",
        "  r,g,b = 0,0,0\n",
        "  for colors in mapping_colors:\n",
        "    c = colors[0]\n",
        "    if int(c) == pixel:\n",
        "      rgb = colors[1]\n",
        "      r,g,b = rgb[1:len(rgb)-1].split(',')\n",
        "      break\n",
        "  return int(r),int(g),int(b)\n",
        "\n",
        "def mapping_labels_color(img,mapping_colors):\n",
        "  for x in range(teste.shape[0]):\n",
        "    for y in range(teste.shape[1]):\n",
        "      if img[x,y,0] != 0:\n",
        "        img[x,y,0],img[x,y,1],img[x,y,2] = set_color(img[x,y,0],mapping_colors)\n",
        "  return img\n",
        "\n",
        "import scipy.io\n",
        "\n",
        "teste = cv2.imread(\"ADEChallengeData2016/annotations/training/ADE_train_00013367.png\")\n",
        "'''teste = cv2.cvtColor(teste, cv2.COLOR_BGR2GRAY)\n",
        "colors = scipy.io.loadmat('color150.mat')['colors']\n",
        "pred_color = colorEncode(teste, colors).astype(np.uint8)\n",
        "\n",
        "plt.imshow(pred_color)#,cmap='gray')   \n",
        "plt.title('img') \n",
        "plt.show()'''\n",
        "\n",
        "mapping_colors = []\n",
        "img_aux = np.zeros((teste.shape),np.uint8)\n",
        "csv_file =  open('color_coding_semantic_segmentation_classes - Sheet1.csv', mode='r')\n",
        "csv_reader = csv.DictReader(csv_file)\n",
        "\n",
        "for row in csv_reader:\n",
        "  mapping_colors.append([row['Idx'],row['Color_Code (R,G,B)']])\n",
        "\n",
        "\n",
        "#print(new_color(1,mapping_colors))\n",
        "for x in range(teste.shape[0]):\n",
        "  for y in range(teste.shape[1]):\n",
        "    teste[x,y,0],teste[x,y,1],teste[x,y,2] = new_color(teste[x,y,0],mapping_colors)\n",
        "\n",
        "plt.imshow(teste)#,cmap='gray')   \n",
        "plt.title('img') \n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}